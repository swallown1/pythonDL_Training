损失函数和优化器的选取
    二分类问题采用交叉熵损失函数(binary_cossentroy)
    多分类问题采用分类损失函数
    回归问题采用均方差损失函数
    时间序列问题采用结合主义时序分类


二分类问题小节：
    在进行数据预处理的时候，应将单词序列转化成二进制向量，也可以编码成其他方式
    带有relu激活层的Dense ，可以解决很多问题。包括情感分类问题。
    二分类问题最后一层一般只有一个神经元，并带有sigmoid激活函数。同时使用交叉熵损失函数 binary_crossentropy
    通常使用rmprop优化器都足够的好。一定要检测模型在数据集之外的表现  如验证数据集上


多分类问题：
       对于标签有两种处理方式，其一是采用one-hot的方式，一般损失函数用categorical_crossentropy
       其二是采用整数标签，一般采用sparse_categorical_crossentropy
       如果有N个分类 则最后一层采用N个分类
       对于多分类问题最后一层采用softmax损失函数，输出每个类别的概率分布
       如果需要将数据划分到许多类别中，应该避免中间层太小，造成信息瓶颈。

回归问题：
        回归问题的损失函数使用MSE 均方误差
        评估治标不同，常用的是使用平方绝对误差(MAE)
        数据如果很少可以用交叉验证的方式评估模型
        如果数据较少，隐藏层使用少一些，防止出现严重的过拟合